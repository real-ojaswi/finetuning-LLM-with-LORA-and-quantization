Finetuned FLAN-T5 with LoRA technique introduced by [Hu et. al](https://arxiv.org/abs/2106.09685). The model with 11B parameters was reduced to 18M parameters. The LoRA finetuning produced rouge1 score of 49.36% after 1 epoch.

Blocks have been adapted from the works at https://github.com/ashishpatel26.
 
